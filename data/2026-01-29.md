<div id=toc></div>

# Table of Contents

- [physics.flu-dyn](#physics.flu-dyn) [Total: 12]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 2]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [physics.optics](#physics.optics) [Total: 11]
- [physics.atom-ph](#physics.atom-ph) [Total: 1]


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [1] [A Practical Computational Hemolysis Model Incorporating Biophysical Properties of the Red Blood Cell Membrane](https://arxiv.org/abs/2601.19994)
*Nico Dirkes,Marek Behr*

Main category: physics.flu-dyn

TL;DR: A strain-based pore modeling approach combining Kelvin-Voigt cell model with biophysical pore formation significantly improves hemolysis prediction accuracy in blood-handling devices compared to conventional stress-based power law models.


<details>
  <summary>Details</summary>
Motivation: Current computational hemolysis models are either inaccurate (deviating by orders of magnitude from experiments) or too computationally expensive for practical use in medical device design, creating a need for accurate yet simple models.

Method: Compared three red blood cell models (stress-based Bludszuweit, simple strain-based Kelvin-Voigt, complex tensor-based TTM) and two hemoglobin release models (power-law and biophysical pore formation) in FDA blood pump and nozzle benchmarks.

Result: The simple strain-based model combined with pore formation model achieved absolute hemolysis predictions within experimental standard deviation, while stress-based power law models deviated by several orders of magnitude.

Conclusion: The strain-based pore modeling approach, incorporating red blood cell membrane viscoelastic properties and biophysical pore formation mechanisms, provides significantly improved hemolysis predictions that can be easily integrated into standard CFD workflows.

Abstract: Purpose: Hemolysis is a key issue in the design of blood-handling medical devices. Computational prediction of this phenomenon is challenging due to the complex multiscale nature of blood. As a result, conventional approaches often fail to predict hemolysis accurately, commonly showing deviations of multiple orders of magnitude compared to experimental data. More accurate models are typically computationally expensive and thus impractical for real-world applications. This work aims to fill this gap by presenting accurate yet simple and efficient computational hemolysis models.
  Methods: Hemolysis modeling relies on two key components: a red blood cell model and a hemoglobin release model. In this work, we compare three red blood cell models: a common stress-based model (Bludszuweit), a simple strain-based model based on the Kelvin-Voigt constitutive law, and a more complex tensor-based model (TTM). Further, we compare two hemoglobin release models: the widely used power-law approach and a biophysical pore formation model.
  Results: We evaluate these models in two benchmark cases: the FDA blood pump and the FDA nozzle. In both benchmarks, the simple strain-based model combined with the pore formation model achieves absolute predictions of hemolysis within the standard deviation of experimental measurements. In contrast, stress-based power law models deviate by several orders of magnitude.
  Conclusion: The strain-based pore modeling approach takes into account the biophysical properties of red blood cell membranes, in particular their viscoelastic deformation behavior and hemoglobin release through membrane pores. This leads to significantly improved hemolysis predictions in a framework that can easily be integrated into common CFD workflows.

</details>


### [2] [A paradox concerning the numerical simulation of Navier-Stokes turbulence](https://arxiv.org/abs/2510.11220)
*Shijie Qin,Kun Xu,Shijun Liao*

Main category: physics.flu-dyn

TL;DR: The paper reveals a paradox in 2D Rayleigh-Bénard convection simulations where time-step variations cause alternating vortical and zonal flow patterns, suggesting numerical noise significantly influences turbulent flow outcomes despite NS equations requiring negligible stochastic disturbances.


<details>
  <summary>Details</summary>
Motivation: To investigate the influence of numerical noise on turbulent flow simulations and reveal a fundamental paradox in how Navier-Stokes equations are applied to turbulence modeling.

Method: Traditional direct numerical simulation (DNS) of 2D Rayleigh-Bénard convection using double precision arithmetic with varying time-steps to observe flow pattern transitions.

Result: Flow types alternate between vortical and zonal patterns as time-step decreases, with statistics differing completely, indicating numerical noise exerts huge influence on final flow type and statistics.

Conclusion: A logical paradox exists between NS turbulence theory (requiring negligible stochastic disturbances) and numerical simulations (where numerical noise significantly affects outcomes), highlighting fundamental issues in turbulence modeling related to the fourth Millennium problem.

Abstract: Two-dimensional Rayleigh-Bénard convection governed by the Navier-Stokes (NS) equations is predicted by traditional direct numerical simulation (DNS) using double precision arithmetic and a range of different time-steps. It is found that the the final flow type tends either to vortical flow or zonal flow, whose statistics are completely different. Notably, these two flow types frequently alternate as the time-step is reduced to a very small value, suggesting that the time-step corresponding to each turbulent flow type should be densely distributed. Thus, stochastic numerical noise exerts a huge influence on the final flow type and statistics of numerically simulated NS turbulence (i.e., turbulence governed by the NS equations) because the time-step has a close relationship with numerical noise. However, the NS equations, as a turbulence model per se, require all small stochastic disturbances for $t>0$ to be negligible. This leads to a logical paradox in the underlying theory. Further investigations are recommended to reveal the essential differences between the exact solution of NS turbulence, numerical simulations of such NS turbulence, and the corresponding actual turbulence. It should be emphasized that NS turbulence is closely related to the fourth Millennium problem, and turbulence is an unsolved fundamental problem in classic mechanics. Hopefully this paradox would be helpful to deepen our understandings about the turbulence and the fourth Millennium problem.

</details>


### [3] [Learning Differentiable Weak-Form Corrections to Accelerate Finite Element Simulations](https://arxiv.org/abs/2601.20019)
*Junoh Jung,Emil Constantinescu*

Main category: physics.flu-dyn

TL;DR: Differentiable weak-form learning approach for accelerating finite element simulations by augmenting momentum equation in variational form with parameterized bilinear operators learned from high-resolution data.


<details>
  <summary>Details</summary>
Motivation: To accelerate finite element simulations while preserving numerical structure and fundamental properties of incompressible flow, avoiding black-box source terms in strong form that can compromise stability and accuracy.

Method: Augment momentum equation directly in variational (weak) form with parameterized bilinear operators whose coefficients are learned from high-resolution simulations. Implemented in Firedrake finite element solver with end-to-end differentiable training via PyTorch-Firedrake coupling.

Result: Weak-form learning yields more accurate and stable solutions over long time horizons than comparable strong-form corrections, improves long-term accuracy while reducing computational cost on benchmark problems (1D convection-diffusion, 2D incompressible Navier-Stokes).

Conclusion: Weak-form learning provides a principled, structure-preserving route to accurate and stable coarse-grid simulations of incompressible flows by aligning learned models with finite element discretization and respecting fundamental flow properties.

Abstract: We present a differentiable weak-form learning approach for accelerating finite element simulations. Rather than introducing black-box source terms in the strong form of the governing equations, we augment the momentum equation directly in the variational (weak) form with parameterized bilinear operators. The coefficients of these operators are learned from high-resolution simulations so that unresolved small-scale dynamics can be represented on coarse grids. Applying the correction at the weak-form level aligns the learned model with the finite element discretization, preserving key numerical structure and better respecting the fundamental properties of incompressible flow. In the same setting, the approach yields solutions that are more accurate and more stable over long time horizons than comparable strong-form corrections. We implement the proposed method in the Firedrake finite element solver and evaluate it on benchmark problems, including the one-dimensional convection-diffusion equation and the two-dimensional incompressible Navier-Stokes equations. End-to-end differentiable training is enabled by coupling PyTorch with the Firedrake adjoint framework. Across these tests, the learned variational operators improve long-term accuracy while reducing computational cost. Overall, our results suggest that weak-form learning provides a principled, structure-preserving route to accurate and stable coarse-grid simulations of incompressible flows.

</details>


### [4] [Mechanisms of particle entrainment in confined gas-particle systems under moving boundaries](https://arxiv.org/abs/2601.20040)
*Arata Hashimoto,Ryosuke Mitani,Toshiki Imatani,Mikio Sakai*

Main category: physics.flu-dyn

TL;DR: Suction-induced particle entrainment in confined gas-particle systems is driven by combined pressure-gradient and unsteady drag forces from boundary-accelerated flow, with entrained mass governed by mechanical work performed on particles rather than peak forces.


<details>
  <summary>Details</summary>
Motivation: Particle entrainment in confined gas-particle systems is crucial for industrial applications (pharmaceutical, food, chemical engineering), but the physical origin of the "suction effect" remains unclear, especially under unsteady flow, strong particle interactions, and transient force networks.

Method: High-fidelity coupled CFD-DEM simulations resolving unsteady gas flow and discrete particle motion with moving boundaries; force decomposition on individual particles; analysis of boundary kinematics variations.

Result: Suction is not purely pressure-driven but results from combined pressure-gradient and unsteady drag forces; entrained mass is governed by mechanical work performed on particle assembly in entrainment direction during boundary motion, not by peak instantaneous forces; boundary kinematics control entrainment by modifying duration of fluid-particle force work.

Conclusion: The study reveals an organizing principle for suction-driven entrainment and establishes a work-based framework for boundary-induced particle transport in confined gas-particle systems, providing fundamental understanding of the suction effect.

Abstract: Particle entrainment in confined gas-particle systems driven by moving boundaries is central to many industrial and natural processes, including pharmaceutical manufacturing, food processing, and chemical engineering. Although often termed a "suction effect," its physical origin remains unclear, especially under unsteady flow, strong particle interactions, and transient force networks. Here we study suction-induced entrainment in a prototypical confined system using high-fidelity coupled CFD-DEM simulations resolving unsteady gas flow and discrete particle motion with moving boundaries. By decomposing the forces on individual particles, we show that suction is not purely pressure-driven, but results from the combined action of pressure-gradient and unsteady drag forces generated by boundary-accelerated flow. Despite the heterogeneous and transient force fields, the final entrained mass is found to be governed primarily by a single energetic measure: the mechanical work performed on the particle assembly in the entrainment direction during boundary motion, rather than by peak instantaneous forces. Varying boundary kinematics demonstrates that changes in displacement or velocity history control entrainment mainly by modifying the duration over which fluid-particle forces perform work. These results reveal an organizing principle for suction-driven entrainment and establish a work-based framework for boundary-induced particle transport in confined gas-particle systems.

</details>


### [5] [Explainable deep learning reveals the physical mechanisms behind the turbulent kinetic energy equation](https://arxiv.org/abs/2601.20052)
*Francisco Alcántara-Ávila,Andrés Cremades,Sergio Hoyas,Ricardo Vinuesa*

Main category: physics.flu-dyn

TL;DR: XDL with SHAP reveals dissipation as dominant organizing mechanism in near-wall turbulence, with hierarchical structure breaking down in outer layer.


<details>
  <summary>Details</summary>
Motivation: To understand physical mechanisms governing turbulent kinetic energy transport using explainable deep learning, specifically investigating how different budget terms relate to coherent structures throughout the channel.

Method: Used explainable deep learning model based on SHAP to identify high-importance structures for turbulent kinetic energy budget terms in turbulent channel flow at Re_τ=125, analyzing spatial relationships between structures for different terms.

Result: Important structures predominantly located in near-wall region, associated with sweep-type events. In viscous layer, production and viscous diffusion structures contained within dissipation structures, showing hierarchical organization. In outer layer, hierarchical organization breaks down with only velocity-pressure-gradient correlation and turbulent transport structures remaining with ~60% spatial coincidence. Classical coherent structures cannot represent mechanisms behind various budget terms.

Conclusion: Dissipation is the dominant organizing mechanism of near-wall turbulence, constraining production and viscous diffusion within a single structural hierarchy that breaks down in the outer layer, revealing limitations of classical coherent structure analysis.

Abstract: In this work, we investigate the physical mechanisms governing turbulent kinetic energy transport using explainable deep learning (XDL). An XDL model based on SHapley Additive exPlanations (SHAP) is used to identify and percolate high-importance structures for the evolution of the turbulent kinetic energy budget terms of a turbulent channel flow at a friction Reynolds number of $Re_τ= 125$. The results show that the important structures are predominantly located in the near-wall region and are more frequently associated with sweep-type events. In the viscous layer, the SHAP structures relevant for production and viscous diffusion are almost entirely contained within those relevant for dissipation, revealing a clear hierarchical organization of near-wall turbulence. In the outer layer, this hierarchical organization breaks down and only velocity-pressure-gradient correlation and turbulent transport SHAP structures remain, with a moderate spatial coincidence of approximately $60\%$. Finally, we show that none of the coherent structures classically studied in turbulence are capable of representing the mechanisms behind the various terms of the turbulent kinetic energy budget throughout the channel. These results reveal dissipation as the dominant organizing mechanism of near-wall turbulence, constraining production and viscous diffusion within a single structural hierarchy that breaks down in the outer layer.

</details>


### [6] [Effect of initial Rayleigh mode on drop deformation and breakup under impulsive acceleration](https://arxiv.org/abs/2601.20248)
*Aditya Parik,Sandip Dighe,Tadd Truscott,Som Dutta*

Main category: physics.flu-dyn

TL;DR: Initial Rayleigh modes in droplets significantly affect breakup under impulsive acceleration through dynamic coupling between free modal oscillations and forced aerodynamic deformation, with constructive superposition amplifying breakup and destructive superposition stabilizing droplets.


<details>
  <summary>Details</summary>
Motivation: While Rayleigh-mode decomposition is fundamental for droplet shape representation and their influence on free oscillation dynamics is well-studied, their role in droplet deformation, breakup, and fragmentation under impulsive acceleration remains largely unexplored.

Method: Using experimentally validated, VOF-based multiphase direct numerical simulations to isolate effects of finite-amplitude surface oscillation modes by initializing drops with well-defined (n,0) modes and phases while conserving volume at finite amplitudes.

Result: Breakup is governed by dynamic coupling between free modal oscillations and forced aerodynamic deformation - constructive superposition strongly amplifies deformation while destructive superposition stabilizes drops even under disruptive forcing. Outcome is controlled by how efficiently external work is partitioned into recoverable oscillatory energy versus center-of-mass translation and viscous dissipation.

Conclusion: Viscosity and density ratio act as key mediators that respectively damp modal interactions and restrict the time window for energy uptake, demonstrating that initial modal state significantly influences droplet breakup dynamics under impulsive acceleration.

Abstract: One of the fundamental ways of representing a droplet shape is through its Rayleigh-mode decomposition, in which each mode corresponds to a distinct surface-energy content. The influence of these modes on free oscillation dynamics has been studied extensively; however, their role in droplet deformation, breakup, and fragmentation under impulsive acceleration remains largely unexplored. Here we systematically quantify how prescribed initial axisymmetric Rayleigh modes affect the deformation and breakup of an impulsively accelerated drop. Using experimentally validated, VOF-based multiphase direct numerical simulations, we isolate the coupled effects of finite-amplitude surface oscillation modes and the associated initial surface-energy state by initializing drops with well-defined $(n,0)$ modes (and phases) while conserving volume at finite amplitudes. We show that breakup is governed not simply by the initial drag of the imposed shape, but by the dynamic coupling between the free modal oscillations and the forced aerodynamic (or shear-driven) deformation: constructive superposition can strongly amplify deformation, whereas destructive superposition can stabilize the drop even under otherwise disruptive forcing. Across all systems studied, the outcome is controlled by how efficiently the external work is partitioned into recoverable oscillatory energy versus centre-of-mass translation and viscous dissipation, with viscosity and density ratio acting as key mediators that respectively damp modal interactions and restrict the time window for energy uptake.

</details>


### [7] [Clustering and surface distributions of buoyant particles in open-channel flows](https://arxiv.org/abs/2601.20258)
*Ana Todorova,Robert K. Niven,Matthias Kramer*

Main category: physics.flu-dyn

TL;DR: Study examines clustering of buoyant particles at air-water interface in turbulent open-channel flow, introducing clustering Weber number to predict behavior and identifying secondary currents as key transport mechanism.


<details>
  <summary>Details</summary>
Motivation: To understand how buoyant particles cluster at air-water interfaces in turbulent open-channel flows, bridging the gap between capillary-driven clustering theory and practical environmental/engineering applications involving particle transport in rivers and channels.

Method: Controlled laboratory flume experiments with two particle types differing in size and density; extension of capillary-based clustering frameworks to open-channel flows by introducing dimensionless clustering Weber number (We_cl) to balance flow-induced disruptive forces and capillary attraction.

Result: Clustering Weber number successfully predicts observed clustering behavior; secondary currents play central role in surface particle transport, producing systematic lateral accumulation dependent on channel aspect ratio.

Conclusion: The study extends capillary-driven clustering theory to open-channel turbulence and identifies secondary currents as a key mechanism controlling particle surface distributions in environmental flows.

Abstract: This study investigates the clustering behaviour and surface distributions of buoyant particles at the air-water interface in open-channel turbulent flow, focusing on the interplay between capillary attraction, hydrodynamic drag, and flow-driven lateral transport. Using controlled laboratory flume experiments, we systematically examine clustering dynamics for two particle types differing in size and density. To interpret the observed behaviour, we extend capillary-based clustering frameworks to open-channel flows by introducing a dimensionless clustering Weber number (We_cl) that captures the balance between the flow-induced disruptive force and capillary attraction, providing a compact description of the observed clustering behaviour. In addition, we demonstrate that secondary currents play a central role in surface particle transport, producing systematic lateral accumulation that depends on channel aspect ratio. Together, these findings extend capillary-driven clustering theory to open-channel turbulence and reveal secondary currents as a key mechanism controlling particle surface distributions.

</details>


### [8] [Effect of wind turbulence on wave generation over a viscous liquid](https://arxiv.org/abs/2601.20396)
*Romain Mathis,Sébastien Cazin,Jeanne Methel,François Charru,Jacques Magnaudet,Frédéric Moisy,Marc Rabaud*

Main category: physics.flu-dyn

TL;DR: Free-stream turbulence increases wrinkle amplitude and reduces critical wind speed for wave formation, but transition occurs at constant friction velocity; wave amplitude varies non-monotonically with fetch due to friction velocity decrease.


<details>
  <summary>Details</summary>
Motivation: To understand how free-stream turbulence in air affects the growth of surface wrinkles and regular waves on viscous liquids, and the transition between these regimes when wind blows over the liquid surface.

Method: Wind tunnel experiments with silicone oil (50× water viscosity), enhanced turbulence using upstream grids (up to 8% intensity), Free-Surface Synthetic Schlieren for surface deformation measurements (micrometer accuracy), hot-wire anemometry above interface, and particle image velocimetry in liquid.

Result: Grid-enhanced turbulence increases wrinkle amplitude and reduces critical wind speed for regular wave onset; wrinkle-wave transition occurs at approximately constant friction velocity; friction velocity decreases with fetch; wave amplitude shows non-monotonic variation with fetch due to this friction velocity decrease.

Conclusion: Free-stream turbulence significantly affects wind-wave generation on viscous liquids by enhancing wrinkle growth and lowering wave onset threshold, while maintaining transition at constant friction velocity; wave energy balance explains non-monotonic amplitude variation with fetch.

Abstract: When wind blows over the surface of a viscous liquid, a clear transition from irregular small-amplitude streamwise-oriented wrinkles to well-defined nearly two-dimensional regular waves is observed at a critical wind velocity. We examine how free-stream turbulence in the air influences the growth of wrinkles and regular waves, as well as the transition between these two regimes. Experiments are carried out in a wind tunnel, in which air is blown over a tank filled with silicone oil whose viscosity is fifty times higher than that of water. The free-stream turbulence is enhanced using upstream grids, achieving relative turbulence intensities up to 8%. Surface deformations are measured using Free-Surface Synthetic Schlieren with micrometer accuracy. Velocity measurements are performed using hot-wire anemometry above the interface and particle image velocimetry in the liquid. Results reveal two primary effects of grid-enhanced free-stream turbulence: an increase in the wrinkle amplitude, and a reduction in the critical wind speed at the onset of regular waves. Nevertheless, the wrinkle-wave transition still corresponds to an approximately constant friction velocity. Similar to a classical boundary layer over a flat plate, the friction velocity is found to decrease with fetch. From a wave energy balance, we develop a qualitative model explaining why, with the highly viscous liquid considered here, this decrease in the friction velocity results in a non-monotonic variation of the wave amplitude with the fetch.

</details>


### [9] [Higher order moments of scalar within a plume in a turbulent boundary layer](https://arxiv.org/abs/2601.20470)
*Miaoyan Pang,Krishna M Talluru,Kapil Chauhan*

Main category: physics.flu-dyn

TL;DR: The gamma distribution is validated as the appropriate PDF for instantaneous scalar concentration in elevated point-source plumes, capturing all statistical moments up to eighth order and extreme events.


<details>
  <summary>Details</summary>
Motivation: To establish a consistent statistical model for instantaneous scalar concentration in turbulent boundary layer plumes, addressing limitations of Gaussian approximations and enabling accurate prediction of higher-order statistics and extreme events.

Method: High-frequency long-duration experimental measurements of neutral/buoyant elevated point-source plumes, extensive validation of two-parameter gamma distribution, analytical extension to higher-order statistics, and statistical convergence analysis.

Result: Gamma distribution accurately captures concentration PDF across all plume locations, predicts central moments up to eighth order, explains extreme event statistics, reveals 1/√2 ratio for mean/RMS half-widths, and demonstrates importance of statistical convergence.

Conclusion: The gamma distribution provides a unified framework for all scalar concentration statistics in elevated point-source plumes within turbulent boundary layers, offering superior statistical modeling compared to classical Gaussian approximations.

Abstract: This study examines the statistical nature of instantaneous scalar concentration in an elevated point-source plume (neutral or buoyant) dispersing within a turbulent boundary layer. Using high-frequency long-duration experimental measurements, we extensively validate the gamma distribution as the appropriate probability density function of concentration, particularly at large scalar magnitudes. The two-parameter gamma distribution is shown to capture the PDF at all locations across the plume. The classical similarity of the mean and root-mean-square (RMS) concentration, often expressed through a Gaussian form, is recovered through similarity of the scale and shape parameters of the gamma distribution. In addition, statistics of extreme events, such as the 99th percentile of the instantaneous concentration signal, are also well predicted, and their observed invariance near the plume centreline is reasoned. Further, similarity is observed for the third- and higher-order central moments and standardised central moments from the experimental data. The framework of the gamma distribution is also analytically extended to higher-order statistics. The experimental data are in good agreement with the predicted central moments up to the eighth order. The results emphasise the importance of achieving statistical convergence for the intermittent concentration signal, directly influenced by finite sampling times in a measurement. A secondary result is obtained for the ratio of plume half-widths based on the mean and the RMS concentration to be $1/\sqrt{2}$, consistent with experimental observations. The results establish the gamma distribution as a consistent and unified model for all scalar concentration statistics in elevated point source plumes within a turbulent boundary layer.

</details>


### [10] [Impact-induced viscoelastic bungee-jumper jets with uniform extension and stress](https://arxiv.org/abs/2601.20558)
*Kyota Kamamoto,Asuka Hosokawa,Yoshiyuki Tagawa*

Main category: physics.flu-dyn

TL;DR: Bungee-jumper jets in dilute PEO solutions show surprisingly uniform extensional rate and stress distributions despite extreme Deborah and Reynolds numbers, suggesting simple constitutive models can effectively represent complex jet dynamics.


<details>
  <summary>Details</summary>
Motivation: To understand the extensional behavior of viscoelastic jets under highly nonequilibrium conditions (large De and Re) where complex dynamics are expected, but where experiments reveal surprisingly simple rheological responses.

Method: High-speed velocimetry and polarization-based stress imaging to measure velocity and stress spatial distributions in dilute PEO solution jets subjected to impulsive forces, creating "bungee-jumper" jets that extend and retract.

Result: Despite extreme De (21-3300) and Re (28-460) conditions, jets exhibit two uniform characteristics: consistent spatial distribution of extensional rate and nearly uniform stress distribution during jetting motion, indicating dynamics can be represented by constitutive models with spatially uniform coefficients.

Conclusion: Complex jet dynamics under extreme extensional conditions can be effectively modeled with simple constitutive equations; the Voigt model provides best agreement with measurements, while the single-spring model captures essential behavior when elasticity dominates.

Abstract: We investigate the dynamics of a "bungee-jumper" jet induced by an impulsive force, which retracts after reaching its peak extension. Despite the strongly extensional and highly nonequilibrium nature of this motion, the jet exhibits simple and uniform rheological responses. To elucidate its extensional behavior in a highly extensional regime quantified by large Deborah and Reynolds numbers ($De \approx 2.1 \times 10^1 - 3.3 \times 10^3$, $Re \approx 2.8 \times 10^1 - 4.6 \times 10^2$), we use high-speed velocimetry and polarization-based stress imaging to measure the spatial distribution of velocity and stress throughout jets made of dilute polyethylene oxide (PEO) solutions. The bungee-jumper jets are found to exhibit two uniform characteristics despite the extreme $De$ conditions: a consistent spatial distribution of the extensional rate and a nearly uniform stress distribution during the jetting motion. These uniformities indicate that the seemingly complex jet dynamics can in fact be effectively represented using a constitutive model with spatially uniform coefficients. Comparison of several viscoelastic models shows that the Voigt model provides the best agreement with the measured dynamics, while the single-spring model captures the essential behavior when elasticity dominates.

</details>


### [11] [Effective longitudinal slip over grooves encapsulated by a nearly inviscid lubricant](https://arxiv.org/abs/2601.20581)
*Ory Schnitzer,Ehud Yariv*

Main category: physics.flu-dyn

TL;DR: Effective slip length calculation for lubricant-encapsulated grooved surfaces with nearly-inviscid lubricant reveals dominant lubricant effects, contrasting with superhydrophobic surfaces.


<details>
  <summary>Details</summary>
Motivation: To understand the hydrodynamic behavior of lubricant-encapsulated surfaces with rectangular grooves under shear flow, particularly in the limit of nearly-inviscid lubricants where viscosity ratio μ is small.

Method: Analytical calculation of effective slip length for periodic rectangular grooves fully wetted by lubricant, focusing on the singular limit of small viscosity ratio μ between lubricant and exterior fluid.

Result: The nearly-inviscid lubricant limit is singular for encapsulated surfaces, indicating dominant lubricant-flow effects, which contrasts sharply with superhydrophobic surfaces where lubricant effects are typically negligible.

Conclusion: Lubricant-encapsulated surfaces exhibit fundamentally different hydrodynamic behavior from superhydrophobic surfaces, with lubricant playing a dominant role in the nearly-inviscid limit, highlighting the importance of considering lubricant effects in such systems.

Abstract: We calculate the effective slip length for a rectangularly grooved periodic surface encapsulated (i.e., fully wetted) by a lubricant fluid and subjected to exterior shear flow parallel to the grooves. Our focus is the limit of a nearly-inviscid lubricant, where the ratio $μ$ of the lubricant viscosity to that of the exterior fluid is small. This limit is singular for an encapsulated surface, indicating a dominant lubricant-flow effect - a stark contrast to superhydrophobic surfaces where the role of the lubricant is typically negligible.

</details>


### [12] [Machine-learning wall model of large-eddy simulation for low- and high-speed flows over rough surfaces](https://arxiv.org/abs/2601.20786)
*Rong Ma,Adrian Lozano-Duran*

Main category: physics.flu-dyn

TL;DR: A neural network-based wall model for LES that incorporates surface roughness effects across low- to high-speed flows, trained on DNS data of rough-wall channel flows, with uncertainty quantification via confidence scores.


<details>
  <summary>Details</summary>
Motivation: Current wall models for large-eddy simulation often lack comprehensive treatment of surface roughness effects across different flow regimes (low- to high-speed, transitional to fully rough), and typically don't provide uncertainty quantification for predictions in extrapolated conditions.

Method: Developed a wall model using an artificial neural network trained on a DNS database of 372 compressible turbulent channel flows over rough walls with various topographies (Gaussian, Weibull distributions). Used information-theoretic dimensionless learning to identify optimal inputs for predicting wall friction and heat flux. Implemented uncertainty quantification through spectrally normalized neural Gaussian process to generate confidence scores.

Result: A-priori evaluation on 110 channel flow cases showed prediction errors below 4%. A-posteriori testing in wall-modeled LES across diverse cases (160+ subsonic/supersonic channel flows, transonic HPT blade, high-speed compression ramp, hypersonic blunt bodies) achieved accuracy within 10% for wall shear stress and 15% for wall heat flux. Model correctly identified reduced performance through confidence score drops in challenging cases.

Conclusion: The proposed neural network-based wall model successfully incorporates roughness effects across wide flow regimes with good predictive accuracy and reliable uncertainty quantification, enabling robust application in complex high-speed flows with rough surfaces.

Abstract: We present a wall model for large-eddy simulation that incorporates surface-roughness effects and is applicable across low- and high-speed flows, for both transitional and fully rough conditions. The model, implemented using an artificial neural network, is trained on a direct numerical simulation database of compressible turbulent channel flows over rough walls. The dataset contains 372 cases spanning a wide range of irregular roughness topographies, including Gaussian and Weibull distributions, Mach numbers 0~3.3, and friction Reynolds numbers 180~2000. We employ an information-theoretic, dimensionless learning method to identify the inputs with the highest predictive power for the dimensionless wall friction and wall heat flux. Predictions are accompanied by a confidence score derived from a spectrally normalized neural Gaussian process, which quantifies uncertainty in regions that deviate from the training dataset. The model performance is first evaluated a-priori on 110 turbulent channel flow cases, yielding prediction errors below 4%. The model is assessed a-posteriori in wall-modeled large-eddy simulations across diverse test cases. These include over 160 subsonic and supersonic turbulent channel flows with rough walls, a transonic high-pressure turbine (HPT) blade with Gaussian roughness, a high-speed compression ramp with sandpaper roughness, and three hypersonic blunt bodies with sand-grain roughness. Results show that the proposed wall model typically achieves a-posteriori predictive accuracy within 10% for wall shear stress and within 15% for wall heat flux, with high confidence in the channel flows and HPT blade cases. In the rough-wall compression ramp and hypersonic blunt bodies, the model captures the heating augmentation with errors ranging 0%~20%. In the cases with the highest errors, the reduced performance is correctly detected by a drop in the confidence score.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [13] [Superelastic Heating in Treanor-Gordiets Plasmas: A Unified Analytic Closure](https://arxiv.org/abs/2601.20734)
*Bernard Parent*

Main category: physics.plasm-ph

TL;DR: Anharmonic gain function derived for non-equilibrium plasmas resolves underestimation of superelastic electron heating by conventional harmonic models, providing thermodynamically consistent closure for electron temperature prediction.


<details>
  <summary>Details</summary>
Motivation: Conventional harmonic models fail to accurately predict superelastic electron heating rates in non-equilibrium plasmas where vibrational temperature exceeds gas temperature, underestimating rates by orders of magnitude due to artificial decoupling of energy modes and ignoring contributions from overpopulated high-lying states in Treanor-Gordiets distributions.

Method: Derived a closed-form, thermodynamically consistent anharmonic gain function based on detailed balance and second-order Dunham expansion, creating a unified governing equation that identifies the kinetic crossover between vibrational-vibrational (V-V) up-pumping and vibrational-translational (V-T) relaxation.

Result: The model accurately predicts the Treanor minimum and recovers the accuracy of full state-to-state benchmarks at a fraction of the computational cost, resolving the limitations of conventional harmonic models that underestimate superelastic electron heating by an order of magnitude or more.

Conclusion: The derived anharmonic gain function provides a robust closure for predicting electron temperature evolution in applications ranging from hypersonic flows to plasma-assisted combustion, offering a unified approach that captures the essential physics of non-equilibrium plasma systems with thermodynamical consistency.

Abstract: In non-equilibrium plasmas where the vibrational temperature exceeds the gas temperature, conventional harmonic models underestimate superelastic electron heating rates by an order of magnitude or more. This failure stems from the artificial decoupling of energy modes, which ignores the exponential heating contributions from overpopulated high-lying states characteristic of Treanor-Gordiets distributions. We resolve this limitation by deriving a closed-form, thermodynamically consistent anharmonic gain function based on detailed balance and a second-order Dunham expansion. This formulation serves as a unified governing equation that naturally identifies the kinetic crossover between vibrational-vibrational (V-V) up-pumping and vibrational-translational (V-T) relaxation. This approach accurately predicts the Treanor minimum and recovers the accuracy of full state-to-state benchmarks at a fraction of the computational cost. The model provides a robust closure for predicting electron temperature evolution in applications ranging from hypersonic flows to plasma-assisted combustion.

</details>


### [14] [Compressible Turbulence as a Source of Particle Beams and Ion Bernstein Waves in Collisionless Plasmas](https://arxiv.org/abs/2601.20842)
*Chuanpeng Hou,Huirong Yan,Siqi Zhao*

Main category: physics.plasm-ph

TL;DR: Compressible plasma turbulence generates suprathermal particles and ion Bernstein waves through transit-time damping at MHD scales and wave excitation at sub-ion scales, explaining observed solar wind proton beams.


<details>
  <summary>Details</summary>
Motivation: To understand the origin of particle beams and ion Bernstein waves in collisionless plasmas, particularly explaining super-Alfvénic proton beams observed in solar wind observations that current models struggle to account for.

Method: High-resolution particle-in-cell (PIC) simulations of compressible turbulence in collisionless plasmas, analyzing energy transfer from MHD scales down to sub-ion scales under realistic solar wind conditions.

Result: Compressible turbulence is damped by transit-time damping at MHD scales, generating suprathermal electrons and proton beams. At sub-ion scales, multiple ion Bernstein wave branches are excited, contributing to proton suprathermal tail formation. These processes remain efficient under solar wind conditions.

Conclusion: Compressive fluctuations, often understudied, are essential for cross-scale energy transfer and dissipation in collisionless plasma turbulence, providing a natural explanation for observed super-Alfvénic proton beams in the solar wind.

Abstract: We investigate the source of particle beams and ion Bernstein waves in collisionless plasmas using a high-resolution particle-in-cell simulation of compressible turbulence. At magnetohydrodynamic (MHD) scales, compressible turbulence is damped by transit-time damping, naturally generating suprathermal electrons and proton beams. As the energy cascade reaches sub-ion scales, multiple branches of ion Bernstein waves are excited and contribute to the formation of proton suprathermal tails. Under realistic conditions such as those in the solar wind, these processes remain efficient and provide a natural explanation for the super-Alfvénic proton beams observed in situ. We show that compressive fluctuations, though often understudied, are essential for cross-scale energy transfer and dissipation in collisionless plasma turbulence.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [15] [Two-Step Diffusion: Fast Sampling and Reliable Prediction for 3D Keller--Segel and KPP Equations in Fluid Flows](https://arxiv.org/abs/2601.20024)
*Zhenda Shen,Zhongjian Wang,Jack Xin,Zhiwen Zhang*

Main category: physics.comp-ph

TL;DR: Two-stage pipeline for fast generative transport in 3D KS/KPP equations: Stage I uses Meanflow-style regressor for one-step global transport, Stage II trains Deep Particle corrector with mini-batch W₂ objective using warm-started OT couplings.


<details>
  <summary>Details</summary>
Motivation: To approximate the map between initial and terminal distributions for 3D KS and KPP equations with fluid flows under Wasserstein metric, while addressing inaccuracy of direct Wasserstein solvers and maintaining one-step efficiency.

Method: Two-stage pipeline: 1) Stage I: Meanflow-style regressor produces deterministic one-step global transport moving particles close to terminal states. 2) Stage II: Freeze initializer and train Deep Particle corrector that directly minimizes mini-batch W₂ objective using warm-started optimal transport couplings computed on Meanflow outputs.

Result: The method stabilizes high-dimensional W₂ computation after one-step transport concentrates mass on approximated correct support. Validated on 3D KS and KPP equations with ordered and chaotic streamline fluid flows.

Conclusion: The proposed two-stage pipeline achieves reliable generative transport for 3D KS/KPP equations by combining efficient one-step transport with explicit W₂ optimization, overcoming limitations of direct Wasserstein solvers while maintaining computational efficiency.

Abstract: We study fast and reliable generative transport for the 3D KS (Keller-Segel) and KPP (Kolmogorov-Petrovsky-Piskunov) equations in the presence of fluid flows with the goal to approximate the map between initial and terminal distributions for a range of physical parameters $σ$ under the Wasserstein metric. To minimize the inaccuracy of direct Wasserstein solver, we propose a two-stage pipeline that retains one-step efficiency while reinstating an explicit $W_2$ objective where it is tractable. In Stage I, a Meanflow-style regressor yields a deterministic, one-step global transport that moves particles close to their terminal states. In Stage II, we freeze this initializer and train a near-identity corrector (Deep Particle, DP) that directly minimizes a mini-batch $W_2$ objective using warm-started optimal transport couplings computed on the Meanflow outputs. Crucially, after the one-step transport (from Stage I) concentrating mass on the approximated correct support, the induced geometry stabilizes high-dimensional $W_2$ computation of the direct Wasserstein solver. We validate our construction in the 3D KS and KPP equations subject to fluid flows with ordered and chaotic streamlines.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [16] [Lateral shearing optical diffraction tomography of brain organoid with reduced spatial coherence](https://arxiv.org/abs/2601.20082)
*Pawel Goclowski,Julianna Winnik,Vishesh Dubey,Piotr Zdankowski,Maciej Trusiak,Ujjwal Neogi,Mukesh Varshney,Balpreet S. Ahluwalia,Azeem Ahmad*

Main category: physics.optics

TL;DR: LS-ODT: A novel common-path interferometric optical diffraction tomography technique using lateral shearing and dynamic speckle illumination for robust 3D refractive index reconstruction of heterogeneous, strongly scattering thick samples like tissues and organoids.


<details>
  <summary>Details</summary>
Motivation: Conventional ODT struggles with heterogeneous, strongly scattering thick samples like tissues and organoids due to multiple scattering effects. There's a need for improved temporal stability and sensitivity for biomedical applications, particularly in histology.

Method: Developed LS-ODT combining: 1) Partial lateral shearing off-axis interferometry (similar to DIC microscopy) to suppress multiple scattering effects, 2) Common-path interferometric design for high temporal stability, 3) Dynamic speckle illumination to enhance spatial phase and RI sensitivity compared to laser-based systems.

Result: Successfully demonstrated on cell phantom, mouse kidney tissue sections, and human iPSC-derived brain organoids in both thin and thick sections. Showed robustness and accuracy across wide sample range. Correlative fluorescence and RI tomography of organoids validated biomedical utility.

Conclusion: LS-ODT effectively addresses limitations of conventional ODT for thick, scattering samples, offering enhanced stability and sensitivity. The technique shows strong potential for supporting biomedical studies, particularly in histology applications with complex biological samples.

Abstract: Optical diffraction tomography (ODT) is a powerful technique for quantitative, label-free reconstruction of the three-dimensional refractive index (RI) distribution of biological samples. While ODT is well established for imaging thin, weakly scattering samples, it encounters significant challenges when applied to heterogeneous, strongly scattering thick samples such as tissues and organoids. In this work, a novel common-path interferometric approach to ODT is presented, specifically designed for the RI reconstruction of heterogeneous and highly scattering samples at high temporal stability. The proposed technique, termed lateral shearing (LS)-ODT, incorporates partial lateral shearing off-axis interferometry to suppress the effects of multiple scattering, similar to the mechanism in differential interference contrast (DIC) microscopy, which is widely used for imaging thick specimens. Additionally, the LS-ODT system uses dynamic speckle illumination to enhance both spatial phase and RI sensitivity compared to laser-based ODT systems. The effectiveness of this method is demonstrated through experiments on a cell phantom. Its robustness and accuracy are further validated across a wide range of samples, including mouse kidney tissue sections and brain organoids derived from human induced pluripotent stem cells (iPSCs), in both thin and thick sections. Furthermore, correlative fluorescence and RI tomography of the organoids highlights the potential of LS-ODT to enhance and support a broad spectrum of biomedical studies, particularly in the field of histology.

</details>


### [17] [Fabrication of high-Q defect-free optical nanofiber photonic crystal resonators](https://arxiv.org/abs/2601.20098)
*Tomofumi Tanaka,Takahiro Suzuki,Owen Mao,Samuel K. Ruddell,Karen E. Webb,Takao Aoki*

Main category: physics.optics

TL;DR: Fabrication of defect-free optical-nanofiber photonic-crystal Fabry-Perot resonators with Q>10^7 using femtosecond laser ablation, showing thermo-optic effects dominate nonlinear properties, enabling potential applications in quantum computing and low-power optical switches.


<details>
  <summary>Details</summary>
Motivation: To create high-quality optical resonators with small mode volumes for applications in quantum information processing and optical switching, addressing the need for efficient cavity QED systems and low-power optical components.

Method: Single-shot femtosecond laser ablation technique for fabricating defect-free optical-nanofiber photonic-crystal Fabry-Perot resonators, with investigation of nonlinear optical properties through pulse interrogation.

Result: Achieved quality factors exceeding 10^7, demonstrated thermo-optic effects dominate within entire cavity bandwidth even with pulses shorter than the 6.6 μs thermal cutoff time.

Conclusion: The high-Q, small mode volume resonators enable potential applications as high-speed quantum nodes for cavity QED-based quantum computing/networking and low-power in-line fiber optical switches.

Abstract: We demonstrate the fabrication of defect-free optical-nanofiber photonic-crystal Fabry-Perot resonators with quality factors exceeding 10^7 using single-shot femtosecond laser ablation. An investigation of the nonlinear optical properties reveals that thermo-optic effects dominate within the entire cavity bandwidth, even when interrogating with pulses one order of magnitude shorter than the 6.6 us thermal cutoff time. The combination of high-Q and small mode volume of these resonators could facilitate the creation of high-speed quantum nodes for cavity QED based quantum computing and networking, as well as low-power in-line fiber optical switches.

</details>


### [18] [Implications of temporal sampling in voltage imaging microscopy](https://arxiv.org/abs/2601.20236)
*Jakub Czuchnowski,Jerome Mertz*

Main category: physics.optics

TL;DR: Analysis shows scanning microscopes excel in low SNR conditions and detecting sparse spikes, while wide-field microscopes perform better with temporal undersampling and detecting most spikes; both converge at high frame rates.


<details>
  <summary>Details</summary>
Motivation: Voltage imaging microscopy has become essential for studying neural activity, but the effects of different temporal sampling methods (point-scanning, line-scanning, wide-field) on signal fidelity haven't been fully investigated, creating a need to understand their inherent advantages and disadvantages for voltage spike detection.

Method: Developed a mathematical framework combining analytical modeling and computer simulations using Monte-Carlo approaches to analyze temporal sampling effects in scanning versus wide-field microscopes.

Result: Scanning microscopes outperform wide-field in low signal-to-noise conditions and when detecting only a small subset of spikes. Wide-field microscopes outperform scanning when measurements are temporally undersampled and a large fraction of spikes needs detection. Both modalities converge in performance as sampling increases and frame rates approach the decay rate of voltage indicators.

Conclusion: Provides guidance for selecting optimal temporal sampling parameters in voltage imaging, with a key recommendation against using scanning voltage imaging microscopes at frame rates below 500 Hz.

Abstract: Significance: Voltage imaging microscopy has emerged as a powerful tool to investigate neural activity both in vivo and in vitro. Various imaging approaches have been developed, including point-scanning, line-scanning and wide-field microscopes, however the effects of their different temporal sampling methods on signal fidelity have not yet been fully investigated. Aim: To provide an analysis of the inherent advantages and disadvantages of temporal sampling in scanning and wide-field microscopes and their effect on the fidelity of voltage spike detection. Approach: We develop a mathematical framework based on a mixture of analytical modeling and computer simulations with Monte-Carlo approaches. Results: Scanning microscopes outperform wide-field microscopes in low signal-to-noise conditions and when only a small subset of spikes needs to be detected. Wide-field microscopes outperform scanning microscopes when the measurement is temporally undersampled and a large fraction of the spikes needs to be detected. Both modalities converge in performance as sampling increases and the frame rate reaches the decay rate of the voltage indicator. Conclusions: Our work provides guidance for the selection of optimal temporal sampling parameters for voltage imaging. Most importantly it advises against using scanning voltage imaging microscopes at frame rates below 500 Hz.

</details>


### [19] [Soft X-ray Reflection Ptychography](https://arxiv.org/abs/2601.20261)
*Damian Guenzing,Dayne Y. Sasaki,Alexander S. Ditter,Abraham L. Levitan,Eric M. Gullikson,Scott Dhuey,Arian Gashi,Hendrik Ohldag,Sujoy Roy,David A. Shapiro,Riccardo Comin,Sophie A. Morley*

Main category: physics.optics

TL;DR: Reflection geometry soft X-ray ptychography enables high-resolution imaging of bulk specimens without transmission constraints, achieving ~45 nm spatial resolution.


<details>
  <summary>Details</summary>
Motivation: Transmission X-ray microscopy and ptychography have thickness limitations that restrict studies of extended/bulk specimens, especially in soft X-ray region. Reflection geometry could overcome these constraints for non-destructive studies.

Method: Developed reflection geometry soft X-ray ptychography using lithographically defined Siemens star and barcode test patterns on multilayer substrates. Used Fourier ring correlation analysis for resolution assessment.

Result: Empirically demonstrated full-pitch spatial resolution of approximately 45 nm from Fourier ring correlation analysis. Established instrumental feasibility and spatial resolution capabilities.

Conclusion: Reflection geometry soft X-ray ptychography is a robust imaging mode that enables non-destructive X-ray studies of materials without requiring transmissive samples, overcoming traditional thickness limitations.

Abstract: Scanning transmission X-ray microscopy and ptychography have become mature tools for high-resolution, element-specific imaging of nanoscale structures. However, transmission geometries impose stringent constraints on sample thickness and preparation, thereby limiting investigations of extended or bulk specimens, especially in the soft X-ray region. Here, we demonstrate reflection geometry soft X-ray ptychography as a robust imaging mode. Instrumental feasibility and spatial resolution are established using a lithographically defined Siemens star and barcode test pattern on a multilayer substrate. We empirically demonstrate a full-pitch spatial resolution of ca. 45 nm from Fourier ring correlation analysis of the reconstructed object. The results highlight the potential of the reflection geometry for nondestructive X-ray studies of materials without the need for transmissive samples.

</details>


### [20] [Lattice-mismatch Moire laser with strong flatband coupling](https://arxiv.org/abs/2601.20272)
*Donghwee Kim,Chiwon Shin,Changi Kim,Gil-Woo Lee,You-Shin No,Jin-Kyu Yang,Heonsu Jeon,Hong-Gyu Park*

Main category: physics.optics

TL;DR: Demonstration of lattice-mismatch Moiré cavities enabling nanolasers via strong flatband coupling, with improved Q factors and stable flatband frequencies compared to twist-angle Moiré structures.


<details>
  <summary>Details</summary>
Motivation: Moiré superlattices can generate flatbands and collective eigenmodes for emergent photonic phenomena, but experimental validation of robust inter-cell interactions and flatband modulation for specific applications remains challenging.

Method: Proposed lattice-mismatch Moiré cavities (vs. twist-angle) with systematic modification of relative lattice parameters. Used photoluminescence for band-structure measurement and cell-resolved spectroscopy to identify flatbands. Achieved mode selection by reducing center-hole size to isolate hexapole mode from degenerate dipole modes.

Result: Lattice-mismatch cavities provide stable flatband frequencies and substantial Q factor enhancement as unit-cell size decreases. Pronounced flatbands observed in small-unit-cell cavities (102 nm mismatch) but not in larger ones (60 nm mismatch). Demonstrated low-threshold hexapole flatband laser in single mode with strong inter-cell coupling maintained.

Conclusion: Systematic modification of relative lattice parameters offers a promising strategy for developing Moiré nanolasers and flatband nanophotonic devices, enabling robust inter-cell coupling and controlled flatband engineering.

Abstract: Inter-cell and/or interlayer coupling in Moire superlattices can generate flatbands and collective eigenmodes that enable emergent physical phenomena, motivating extensive exploration of Moire-inspired photonic devices. However, the experimental validation of robust inter-cell interactions in Moire photonic structures and the modulation of flatbands for specific photonic applications remain challenging. Here, we propose a lattice-mismatch Moire cavity and demonstrate nanolasers enabled by strong flatband coupling. In contrast to a twist-angle Moire cavity, a lattice-mismatch Moire cavity provides a stable flatband frequency and a substantial enhancement in Q factor compared to an isolated single-cell cavity, as the unit-cell size decreases. The photonic band-structure measurement of the small-unit-cell Moire cavity by photoluminescence reveals pronounced flatbands. Cell-resolved spectroscopy further confirms the presence of flatbands by identifying resonant peaks that consistently emerge across unit cells in a Moire cavity with a lattice mismatch of 102 nm, but not in a larger-unit-cell Moire cavity with a mismatch of 60 nm. Furthermore, mode selection is achieved by reducing the center-hole size, thus isolating the hexapole mode from the degenerate dipole modes while maintaining strong inter-cell coupling. Consequently, we demonstrate a low-threshold hexapole flatband laser in a single mode. Therefore, the systematic modification of the relative lattice parameters of the two constituent lattices offers a promising strategy for developing Moire nanolasers and flatband nanophotonic devices.

</details>


### [21] [Controlling X-ray emission with dispersion-engineered surface plasmon polaritons](https://arxiv.org/abs/2601.20337)
*H. Aknin,Y. Klein,S. Shwartz*

Main category: physics.optics

TL;DR: Controlling hard x-ray emission via entanglement with engineered ultraviolet surface plasmon polaritons using metal-dielectric multilayers on nonlinear crystals.


<details>
  <summary>Details</summary>
Motivation: To achieve compact, designable control over x-ray emission patterns (angular and spectral distribution) by leveraging quantum entanglement and engineered surface plasmon polaritons, extending capabilities in nonlinear and quantum x-ray optics.

Method: Using spontaneous parametric down-conversion of an x-ray pump to generate correlated hard x-ray signal photons and ultraviolet SPP modes near resonance, with SPP dispersion engineered via metal-dielectric multilayer structures on nonlinear crystals.

Result: Engineering SPP dispersion reshapes the phase-matching landscape and imprints tunable angular-spectral structure on emitted x-ray photons, enabling controlled x-ray emission patterns.

Conclusion: The scheme provides compact, designable control of x-ray emission and extends surface-plasmon-assisted nonlinear and quantum x-ray optics capabilities.

Abstract: We propose controlling the angular and spectral distribution of hard x-ray emission by entangling x-ray photons with ultraviolet surface plasmon polaritons (SPPs) whose dispersion is engineered by a metal-dielectric multilayer on a nonlinear crystal. Spontaneous parametric down-conversion of an x-ray pump produces a hard x-ray signal photon correlated with an ultraviolet SPP mode near its resonance. Engineering the SPPs dispersion reshapes the phase-matching landscape and imprints tunable angular-spectral structure on the emitted x-ray photons. The scheme enables compact, designable control of x-ray emission and extends surface-plasmon-assisted nonlinear and quantum x-ray optics.

</details>


### [22] [Zero-Order Diffraction Suppression in Full Field-of-View Computer Generated Holography: A Camera In the Loop Interferometric Approach](https://arxiv.org/abs/2601.20376)
*Alessandro Cerioni,Samuele Trezzi,Marco Astarita,Tommaso Ongarello,Anna Cesaratto,Giulio Cerullo,Andrea Bassi,Gianluca Valentini,Paolo Pozzi*

Main category: physics.optics

TL;DR: Novel interferometric method suppresses zero-order diffraction in phase-only holography using destructive interference and camera-in-the-loop calibration, achieving 99% suppression without image quality loss.


<details>
  <summary>Details</summary>
Motivation: Zero-order diffraction (ZOD) has been a long-standing barrier to practical deployment of full-field holography, limiting the development of compact, high-fidelity holographic engines for augmented and mixed reality displays.

Method: Interferometric approach using destructive interference between zeroth-order light and suppression beam in plane conjugated to SLM. Camera-in-the-loop calibration retrieves optimal pixel-wise phase map to cancel ZOD while preserving full SLM modulation depth.

Result: Experimental demonstrations achieve up to 99% suppression of ZOD intensity without loss of image quality or field of view. Correction can be applied to any hologram without recomputation, enabling real-time operation and robust performance.

Conclusion: Method removes barrier to practical deployment of full-field holography, facilitating development of compact, high-fidelity holographic engines for augmented and mixed reality displays.

Abstract: We introduce a novel interferometric approach for suppressing zero-order diffraction (ZOD) in phase-only computer-generated holography. The technique relies on the destructive interference between the zeroth-order light and a suppression beam in a plane optically conjugated to the spatial light modulator (SLM). A camera-in-the-loop (CITL) calibration procedure retrieves the optimal pixel-wise phase map that cancels out the ZOD component with high precision, while preserving the full modulation depth of the SLM. Experimental demonstrations on point-cloud and 2D/3D holograms achieve up to 99% suppression of the ZOD intensity, without loss of image quality or field of view. Once calibrated, the correction can be applied to any hologram without recomputation, enabling real-time operation and robust performance over time. This method removes a long-standing barrier to the practical deployment of full-field holography, facilitating the development of compact, high-fidelity holographic engines for augmented and mixed reality displays.

</details>


### [23] [Temporal Paraxial Optics under Adiabatic Modulations](https://arxiv.org/abs/2601.20485)
*Antonio Alex-Amor,Carlos Molero*

Main category: physics.optics

TL;DR: Temporal paraxial formulation for ultrashort pulse propagation in time-modulated media with slowly varying refractive index, extending paraxial optics beyond time-invariant backgrounds.


<details>
  <summary>Details</summary>
Motivation: To develop a framework for understanding and controlling ultrashort optical pulse propagation in time-modulated media, extending traditional paraxial optics beyond time-invariant backgrounds typically treated in frequency domain.

Method: Derived paraxial wave equation directly in time domain from Helmholtz equation under adiabatic approximation, resulting in Schrödinger-like structure; developed Green's-function description, operator-based Hamiltonian formalism, and ABCD matrix representation for temporal propagation.

Result: Obtained analytically tractable model with closed-form solutions for ultrashort Gaussian pulses; demonstrated that temporal modulation provides active control over pulse dynamics including temporal width and chirp evolution.

Conclusion: Temporal modulation offers active control mechanism for ultrashort pulse shaping with applications in ultrafast optics and connection to temporal wave-packet dynamics.

Abstract: This paper presents a temporal paraxial formulation for the propagation of ultrashort optical pulses in time-modulated media with slowly varying refractive index. By deriving the paraxial wave equation directly in the time domain from the Helmholtz equation under an adiabatic approximation, the model remains analytically tractable while extending paraxial optics beyond time-invariant backgrounds commonly treated by frequency-domain expansions. The resulting equation preserves a Schrödinger-like structure in the presence of explicit temporal modulation and admits closed-form solutions for ultrashort Gaussian pulses. The framework supports a Green's-function description and an operator-based Hamiltonian formalism, from which an ABCD matrix representation for temporal propagation in time-varying media is obtained. The results demonstrate that temporal modulation provides an active means to control ultrashort pulse dynamics, enabling tailored evolution of pulse characteristics such as temporal width and chirp, with potential applications in ultrafast pulse shaping and a direct connection to temporal wave-packet dynamics.

</details>


### [24] [Single-Shot Multispectral Mid-Infrared Imaging with Incoherent Light via Adiabatic Upconversion](https://arxiv.org/abs/2601.20570)
*Daniel Beitner,Ziv Abelson,Eyal Hollander,Omri Meron,Haim Suchowski*

Main category: physics.optics

TL;DR: First demonstration of single-shot, room-temperature multispectral mid-IR (2-5 μm) imaging using adiabatic sum-frequency conversion to up-convert incoherent thermal light to visible wavelengths for detection on Silicon sensors.


<details>
  <summary>Details</summary>
Motivation: Current mid-IR cameras have critical limitations: require cryogenic cooling, limited pixel resolution, high cost, and restricted spectral access. Optical up-conversion offers a solution but existing systems rely on narrowband phase matching, mechanical scanning, or angular tuning, limiting imaging speed and practicality.

Method: Adiabatic sum-frequency conversion enables simultaneous conversion of the entire 2-5 μm spectral region into the visible domain. The system captures images on Silicon detectors with spatial resolution below 20 μm and high angular tolerance, operating at room temperature without scanning or cryogenic cooling.

Result: Demonstrated single-shot multispectral mid-IR imaging of incoherent thermal light. Validated full-field imaging using USAF resolution target. Achieved spectroscopic contrast imaging in dielectric metamaterials by resolving wavelength and polarization dependent scattering resonances.

Conclusion: This compact, robust approach bridges laboratory-grade infrared sensors with scalable Silicon-based detection technologies suitable for real-world deployment, overcoming limitations of current mid-IR imaging systems.

Abstract: Multispectral mid-infrared (2-5 ${μm}$) imaging is a critical capability across science and technology, offering a window into the vibrational and thermal landscape of matter that is inaccessible to visible sensors. It bridges the microscopic world of molecular interactions with macroscopic sensing technologies, with applications in environmental sensing, defense and molecular diagnostics. However, current mid-IR cameras require cryogenic cooling and exhibit limited pixel resolution, high cost, and restricted spectral access. Optical up-conversion provides a pathway to overcome these limitations, but existing systems typically rely on narrowband phase matching, mechanical scanning, or angular tuning, limiting imaging speed and practicality. Here, we demonstrate the first single-shot, room-temperature multispectral mid-IR imaging of incoherent thermal light enabled by adiabatic sum-frequency conversion. Our system simultaneously converts the entire (2-5 ${μm}$) region into the visible domain, capturing the image on a Silicon detector with spatial resolution below 20 ${μm}$ and high angular tolerance. We validate full-field imaging using a USAF resolution target and demonstrate spectroscopic contrast imaging in dielectric metamaterials by resolving wavelength and polarization dependent scattering resonances, all achieved without scanning, thermal control, or cryogenic operation. This compact and robust approach bridges the gap between laboratory-grade infrared sensors and scalable Silicon-based detection technologies suitable for real-world deployment.

</details>


### [25] [Quantum Squeezing Enhanced Photothermal Microscopy](https://arxiv.org/abs/2601.20632)
*Pengcheng Fu,Xiao Liu,Siming Wang,Nan Li,Chenran Xu,Han Cai,Huizhu Hu,Vladislav V. Yakovlev,Xu Liu,Shi-Yao Zhu,Xingqi Xu,Delong Zhang,Da-Wei Wang*

Main category: physics.optics

TL;DR: Squeezing-enhanced photothermal (SEPT) microscopy uses twin-beam quantum correlations to achieve 3.5 dB noise suppression beyond the standard quantum limit for label-free absorption imaging.


<details>
  <summary>Details</summary>
Motivation: Label-free optical microscopy through absorption or scattering spectroscopy is fundamentally limited by photon shot noise. While quantum nonlinear microscopy shows sub-shot-limited sensitivity, it's limited by availability of high peak-power squeezed light sources.

Method: SEPT microscopy leverages twin-beam quantum correlations to detect absorption-induced signals. It combines continuous-wave squeezing with photothermal modulation, providing versatility and compatibility with existing microscopy platforms.

Result: SEPT achieves 3.5 dB noise suppression beyond the standard quantum limit, enabling 2.5-fold increase in imaging throughput or 31% reduction in pump power. It successfully characterizes nanoparticles and reveals subcellular structures like cytochrome c that are undetectable under shot-noise-limited imaging.

Conclusion: SEPT establishes a new paradigm for molecular absorption imaging by combining label-free contrast, quantum-enhanced sensitivity, and compatibility with existing microscopy platforms, with far-reaching implications in cellular biology, nanoscience, and materials characterization.

Abstract: Label-free optical microscopy through absorption or scattering spectroscopy provides fundamental insights across biology and materials science, yet its sensitivity remains fundamentally limited by photon shot noise. While recent demonstrations of quantum nonlinear microscopy show sub-shot-limited sensitivity, they are intrinsically limited by availability of high peak-power squeezed light sources. Here, we introduce squeezing-enhanced photothermal (SEPT) microscopy, a quantum imaging technique that leverages twin-beam quantum correlations to detect absorption induced signals with unprecedented sensitivity. SEPT achieves 3.5 dB noise suppression beyond the standard quantum limit, enabling a 2.5-fold increase in imaging throughput or 31% reduction in pump power, while providing an unmatched versatility through the intrinsic compatibility between continuous-wave squeezing and photothermal modulation. We showcase SEPT applications by providing high-precision characterization of nanoparticles and revealing subcellular structures, such as cytochrome c, that remain undetectable under shot-noise-limited imaging. By combining label-free contrast, quantum-enhanced sensitivity, and compatibility with existing microscopy platforms, SEPT establishes a new paradigm for molecular absorption imaging with far-reaching implications in cellular biology, nanoscience, and materials characterization.

</details>


### [26] [Photoacoustic Tensile Imaging](https://arxiv.org/abs/2601.20712)
*Daohuai Jiang,Xuanxuan Ye,Hengrong Lan,Xianzeng Zhang,Fei Gao*

Main category: physics.optics

TL;DR: A new photoacoustic tensile imaging (PATI) modality is proposed that enables quantitative assessment of tensile stress in biological samples using nonlinear photoacoustic responses to dual-pulse laser excitation.


<details>
  <summary>Details</summary>
Motivation: Current photoacoustic imaging methods primarily focus on optical absorption properties, while tensile measurement based on photoacoustic effects remains unexplored. There is a need for quantitative assessment of tensile stress in biological tissues for biomedical applications like vascular pressure monitoring.

Method: PATI exploits nonlinear photoacoustic responses induced by dual-pulse laser excitation. It establishes a mapping between applied tension and the increment of nonlinear PA signal by varying the temporal delay between heating and detecting laser pulses, quantitatively analyzing the relationship between tensile force and nonlinear PA characteristics.

Result: Phantom experiments demonstrate a strong correlation between nonlinear PA signal intensity and applied tensile force, confirming the feasibility of the proposed approach for tensile force monitoring.

Conclusion: PATI represents a new photoacoustic imaging modality with potential for biomedical applications requiring quantitative tensile stress assessment, particularly in vascular pressure monitoring and other functional imaging applications.

Abstract: Photoacoustic (PA) imaging combines the high optical absorption contrast of optical imaging with the deep tissue penetration of ultrasound detection, offering great potential for functional imaging and disease diagnosis. However, current PA imaging methods mainly explore optical absorption properties of biological tissue. To the best of our knowledge, tensile measurement based on PA effect is still an untapped area to be explored. In this work, we propose photoacoustic tensile imaging (PATI), a new PA imaging modality enabling quantitative assessment of tensile stress in biological samples. PATI exploits the nonlinear PA response induced by dual-pulse laser excitation to establish a mapping between the applied tension and the increment of the nonlinear PA signal. By varying the temporal delay between the heating and detecting laser pulses, the relationship between tensile force and nonlinear PA characteristics is quantitatively analyzed. Phantom experiments demonstrate a strong correlation between the nonlinear PA signal intensity and the applied tensile force. These results confirm the feasibility of the proposed approach for tensile force monitoring, which holds potential in biomedical applications, such as vascular pressure monitoring.

</details>


<div id='physics.atom-ph'></div>

# physics.atom-ph [[Back]](#toc)

### [27] [Development of a Quantum Blackbody Thermometer toward Primary On-orbit Thermometry](https://arxiv.org/abs/2601.20607)
*Peter J. Beierle,Denis Tremblay,Noah Schlossberger,Christopher L. Holloway,Stephen P. Eckel,Eric B. Norrgard*

Main category: physics.atom-ph

TL;DR: Quantum blackbody thermometer using rubidium atom fluorescence ratios achieves 30 mK accuracy, surpassing resistance-based thermometers by leveraging immutable atomic properties for long-term stability.


<details>
  <summary>Details</summary>
Motivation: Existing resistance-based thermometers (like platinum resistance thermometers) can be calibrated with high accuracy but suffer from temporal drift and handling-induced shifts, limiting long-term stability. There's a need for intrinsically calibrated thermometers with guaranteed long-term accuracy.

Method: Quantum blackbody thermometer based on measuring fluorescence ratios of optically excited rubidium atoms in microfabricated vapor cells. The approach leverages the immutable physical properties (transition strengths) of rubidium atoms to ensure long-term stability.

Result: Roadmap to a deployable thermometer achieving long-term accuracy of 30 mK, exceeding existing on-orbit resistance-based thermometers. The quantum approach provides intrinsic calibration through atomic properties.

Conclusion: Quantum blackbody thermometers using atomic fluorescence ratios offer superior long-term stability compared to resistance-based thermometers by eliminating drift and handling-induced shifts through reliance on immutable atomic properties.

Abstract: We present a roadmap to a deployable, intrinsically calibrated thermometer with long-term accuracy of 30 mK, exceeding existing on-orbit resistance-based thermometers. Our quantum blackbody thermometer is based on measuring fluorescence ratios of optically excited rubidium atoms in microfabricated vapor cells. The key advantage of the quantum blackbody thermometer is that long-term stability of the fluorescence ratios is guaranteed by the immutable physical properties (transition strengths) of the rubidium atom. This should be compared against resistance-based thermometers, such as platinum resistance thermometers, which may be calibrated with exceptional accuracy but are susceptible to temporal drift and shifts due to improper handling.

</details>
